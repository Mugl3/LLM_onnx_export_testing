{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start by creating ONNX model from transformers embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is assumed that you are already in the local path where your model files have been downloaded to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in f:\\github\\onnx_export\\venv\\lib\\site-packages (4.40.2)\n",
      "Requirement already satisfied: evaluate in f:\\github\\onnx_export\\venv\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: mkl-include in f:\\github\\onnx_export\\venv\\lib\\site-packages (2024.1.0)\n",
      "Requirement already satisfied: mkl in f:\\github\\onnx_export\\venv\\lib\\site-packages (2021.4.0)\n",
      "Collecting mkl\n",
      "  Downloading mkl-2024.1.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: optimum[onnxruntime-gpu] in f:\\github\\onnx_export\\venv\\lib\\site-packages (1.19.2)\n",
      "Requirement already satisfied: coloredlogs in f:\\github\\onnx_export\\venv\\lib\\site-packages (from optimum[onnxruntime-gpu]) (15.0.1)\n",
      "Requirement already satisfied: sympy in f:\\github\\onnx_export\\venv\\lib\\site-packages (from optimum[onnxruntime-gpu]) (1.12)\n",
      "Requirement already satisfied: torch>=1.11 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from optimum[onnxruntime-gpu]) (2.3.0)\n",
      "Requirement already satisfied: packaging in f:\\github\\onnx_export\\venv\\lib\\site-packages (from optimum[onnxruntime-gpu]) (24.0)\n",
      "Requirement already satisfied: numpy in f:\\github\\onnx_export\\venv\\lib\\site-packages (from optimum[onnxruntime-gpu]) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from optimum[onnxruntime-gpu]) (0.23.0)\n",
      "Requirement already satisfied: datasets in f:\\github\\onnx_export\\venv\\lib\\site-packages (from optimum[onnxruntime-gpu]) (2.19.1)\n",
      "Requirement already satisfied: onnx in f:\\github\\onnx_export\\venv\\lib\\site-packages (from optimum[onnxruntime-gpu]) (1.16.0)\n",
      "Requirement already satisfied: onnxruntime-gpu>=1.11.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from optimum[onnxruntime-gpu]) (1.17.1)\n",
      "Requirement already satisfied: protobuf>=3.20.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from optimum[onnxruntime-gpu]) (4.25.3)\n",
      "Requirement already satisfied: accelerate in f:\\github\\onnx_export\\venv\\lib\\site-packages (from optimum[onnxruntime-gpu]) (0.30.1)\n",
      "Requirement already satisfied: filelock in f:\\github\\onnx_export\\venv\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in f:\\github\\onnx_export\\venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: dill in f:\\github\\onnx_export\\venv\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in f:\\github\\onnx_export\\venv\\lib\\site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: xxhash in f:\\github\\onnx_export\\venv\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in f:\\github\\onnx_export\\venv\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\n",
      "Collecting intel-openmp==2024.* (from mkl)\n",
      "  Downloading intel_openmp-2024.1.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tbb==2021.* in f:\\github\\onnx_export\\venv\\lib\\site-packages (from mkl) (2021.11.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from datasets->optimum[onnxruntime-gpu]) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in f:\\github\\onnx_export\\venv\\lib\\site-packages (from datasets->optimum[onnxruntime-gpu]) (0.6)\n",
      "Requirement already satisfied: aiohttp in f:\\github\\onnx_export\\venv\\lib\\site-packages (from datasets->optimum[onnxruntime-gpu]) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum[onnxruntime-gpu]) (4.11.0)\n",
      "Requirement already satisfied: flatbuffers in f:\\github\\onnx_export\\venv\\lib\\site-packages (from onnxruntime-gpu>=1.11.0->optimum[onnxruntime-gpu]) (24.3.25)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: networkx in f:\\github\\onnx_export\\venv\\lib\\site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (3.1.3)\n",
      "Requirement already satisfied: intel-openmp==2021.* in f:\\github\\onnx_export\\venv\\lib\\site-packages (from mkl) (2021.4.0)\n",
      "Requirement already satisfied: colorama in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from transformers[sentencepiece]<4.41.0,>=4.26.0->optimum[onnxruntime-gpu]) (0.2.0)\n",
      "Requirement already satisfied: psutil in f:\\github\\onnx_export\\venv\\lib\\site-packages (from accelerate->optimum[onnxruntime-gpu]) (5.9.8)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from coloredlogs->optimum[onnxruntime-gpu]) (10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from sympy->optimum[onnxruntime-gpu]) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (1.9.4)\n",
      "Requirement already satisfied: pyreadline3 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->optimum[onnxruntime-gpu]) (3.4.1)\n",
      "Requirement already satisfied: six>=1.5 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from jinja2->torch>=1.11->optimum[onnxruntime-gpu]) (2.1.5)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: rich in f:\\github\\onnx_export\\venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in f:\\github\\onnx_export\\venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in f:\\github\\onnx_export\\venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in f:\\github\\onnx_export\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB 640.0 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.7 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.1/1.7 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 7.8 MB/s eta 0:00:00\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.16.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install \"optimum[onnxruntime]==1.5.0\" transformers evaluate mkl-include mkl --upgrade\n",
    "!pip install \"optimum[onnxruntime-gpu]\" transformers evaluate mkl-include mkl --upgrade\n",
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\GitHub\\onnx_export\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `from_transformers` is deprecated, and will be removed in optimum 2.0.  Use `export` instead\n",
      "Framework not specified. Using pt to export the model.\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "\n",
      "***** Exporting submodel 1/1: RobertaModel *****\n",
      "Using framework PyTorch: 2.3.0+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('onnx_opt\\\\tokenizer_config.json',\n",
       " 'onnx_opt\\\\special_tokens_map.json',\n",
       " 'onnx_opt\\\\vocab.json',\n",
       " 'onnx_opt\\\\merges.txt',\n",
       " 'onnx_opt\\\\added_tokens.json',\n",
       " 'onnx_opt\\\\tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optimum.onnxruntime import ORTModelForFeatureExtraction\n",
    "from transformers import AutoTokenizer\n",
    "from pathlib import Path\n",
    " \n",
    " \n",
    "model_id=\"./\"\n",
    "onnx_path = Path(\"onnx_opt\")\n",
    " \n",
    "# load vanilla transformers and convert to onnx\n",
    "model = ORTModelForFeatureExtraction.from_pretrained(model_id, from_transformers=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    " \n",
    "# save onnx checkpoint and tokenizer\n",
    "model.save_pretrained(onnx_path)\n",
    "tokenizer.save_pretrained(onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for inferencing, creating custom functions to allow encode from pytorch esque to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Pipeline\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    " \n",
    "# copied from the model card\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    " \n",
    " \n",
    "class SentenceEmbeddingPipeline(Pipeline):\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        # we don't have any hyperameters to sanitize\n",
    "        preprocess_kwargs = {}\n",
    "        return preprocess_kwargs, {}, {}\n",
    " \n",
    "    def preprocess(self, inputs):\n",
    "        encoded_inputs = self.tokenizer(inputs, padding=True, truncation=True, return_tensors='pt')\n",
    "        return encoded_inputs\n",
    " \n",
    "    def _forward(self, model_inputs):\n",
    "        outputs = self.model(**model_inputs)\n",
    "        return {\"outputs\": outputs, \"attention_mask\": model_inputs[\"attention_mask\"]}\n",
    " \n",
    "    def postprocess(self, model_outputs):\n",
    "        # Perform pooling\n",
    "        sentence_embeddings = mean_pooling(model_outputs[\"outputs\"], model_outputs['attention_mask'])\n",
    "        # Normalize embeddings\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        return sentence_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the previously loaded & converted model (without loading local ONNX save file), for inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0446, -0.0113, -0.0328, -0.0394, -0.0135])\n"
     ]
    }
   ],
   "source": [
    "# init pipeline\n",
    "vanilla_emb = SentenceEmbeddingPipeline(model=model, tokenizer=tokenizer)\n",
    " \n",
    "# run inference\n",
    "pred = vanilla_emb(\"Could you assist me in finding my lost card?\")\n",
    " \n",
    "# print an excerpt from the sentence embedding\n",
    "print(pred[0][:5])\n",
    "#     tensor([-0.0631,  0.0426,  0.0037,  0.0377,  0.0414])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On local terminal, CD into the ONNX path where the new files are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load locally saved ONNX model & run inferencing on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `from_transformers` is deprecated, and will be removed in optimum 2.0.  Use `export` instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0446, -0.0113, -0.0328, -0.0394, -0.0135])\n"
     ]
    }
   ],
   "source": [
    "#Load from the ONNX saved path a model for inferencing\n",
    "\n",
    "model_id=\"./onnx_opt/\"\n",
    "onnx_path = Path(\"./\")\n",
    " \n",
    "# load vanilla transformers and convert to onnx\n",
    "model = ORTModelForFeatureExtraction.from_pretrained(model_id, from_transformers=False)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# init pipeline\n",
    "vanilla_emb = SentenceEmbeddingPipeline(model=model, tokenizer=tokenizer)\n",
    " \n",
    "# run inference\n",
    "pred = vanilla_emb(\"Could you assist me in finding my lost card?\")\n",
    " \n",
    "# print an excerpt from the sentence embedding\n",
    "print(pred[0][:5])\n",
    "#     tensor([-0.0631,  0.0426,  0.0037,  0.0377,  0.0414])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
